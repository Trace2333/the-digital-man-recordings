# Attention

注意力机制目前在各种领域的研究中都发挥了非常重要的作用，它本身具有可解释性并且效果明显，因此研究它势在必行。

但是在各种的研究中，attention通常直接嵌入到模型中，导致初学该机制的同学很难直接了解它到底怎么实现，所以这个文档将会会注意力机制作一个系统的说明，并传授如何实现该机制，并分享该机制的official代码。

之后的内容将会以自注意力（self-attention）机制为研究对象。

## 一、简介

注意力机制，即Attention是近年来在深度学习中应用广泛的一种技术，它本身不能算作神经网络，但是能够对神经网络的结果做出比较可观的提升，其核心在于注意力分数和KQV矩阵。

该机制对序列或者二维图片进行序列建模，指出序列中的关系，允许网络对输入的依赖关系建模，但不考虑元素在输入和输出中的距离，将一个序列的特定元素与其他所有元素串联起来。

## 二、过程

就像它自己的名字所说，注意力即在特定的位置添加更多的重心，



