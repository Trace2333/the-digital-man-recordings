

## 实验记录

```Python
初始状态
batch_size = 64    # 基本参数
input_size = 300
alpha = 0.3
hiden_size1 = 300
hiden_size2 = 300
loss1 = 0
loss2 = 0
loss = 0
epochs = 1
evaluation_epochs = 1
lr = 1e-3


Run summary:
wandb:       Sentence Precision 0.60938
wandb:       Sequence Precision 0.64062
wandb:  Train Sentence F1 Score 0.55853
wandb: Train Sentence Precision 0.46875
wandb:    Train Sentence Recall 0.69231
wandb:  Train Sequence F1 Score 0.58016
wandb: Train Sequence Precision 0.5
wandb:    Train Sequence Recall 0.69231
wandb:                      lr: 0.001
wandb:          train Totalloss 0.10662
wandb:              train loss1 0.08891
wandb:              train loss2 0.1142
```







```Python
#lr=1e-3
Run summary:
wandb:       Sentence Precision 0.60938
wandb:       Sequence Precision 0.64062
wandb:  Train Sentence F1 Score 0.55853
wandb: Train Sentence Precision 0.46875
wandb:    Train Sentence Recall 0.69231
wandb:  Train Sequence F1 Score 0.58016
wandb: Train Sequence Precision 0.5
wandb:    Train Sequence Recall 0.69231
wandb:                      lr: 0.001
wandb:          train Totalloss 0.10662
wandb:              train loss1 0.08891
wandb:              train loss2 0.1142
    
#lr=2e-3

wandb: Run summary:
wandb:       Sentence Precision 0.65625
wandb:       Sequence Precision 0.64062
wandb:  Train Sentence F1 Score 0.75179
wandb: Train Sentence Precision 0.67188
wandb:    Train Sentence Recall 0.85455
wandb:  Train Sequence F1 Score 0.73179
wandb: Train Sequence Precision 0.64062
wandb:    Train Sequence Recall 0.85455
wandb:                      lr: 0.002
wandb:          train Totalloss 0.08008
wandb:              train loss1 0.05436
wandb:              train loss2 0.0911
wandb: 

#lr = 1e-4

wandb: Run summary:
wandb:       Sentence Precision 0.5625
wandb:       Sequence Precision 0.53125
wandb:  Train Sentence F1 Score 0.53993
wandb: Train Sentence Precision 0.45312
wandb:    Train Sentence Recall 0.66935
wandb:  Train Sequence F1 Score 0.52867
wandb: Train Sequence Precision 0.4375
wandb:    Train Sequence Recall 0.66935
wandb:                      lr: 0.0001
wandb:          train Totalloss 0.10679
wandb:              train loss1 0.09013
wandb:              train loss2 0.11392
wandb: 
    
#lr=2e-4
wandb: Run summary:
wandb:  Train Sentence F1 Score 0.46208
wandb: Train Sentence Precision 0.375
wandb:    Train Sentence Recall 0.60345
wandb:  Train Sequence F1 Score 0.50676
wandb: Train Sequence Precision 0.4375
wandb:    Train Sequence Recall 0.60345
wandb:                      lr: 0.0002
wandb:          train Totalloss 0.12239
wandb:              train loss1 0.1004
wandb:              train loss2 0.13181
wandb: 

#lr=1e-5

wandb: Run summary:
wandb:       Sentence Precision 0.23438
wandb:       Sequence Precision 0.125
wandb:  Train Sentence F1 Score 0.14573
wandb: Train Sentence Precision 0.09375
wandb:    Train Sentence Recall 0.33058
wandb:  Train Sequence F1 Score 0.16399
wandb: Train Sequence Precision 0.10938
wandb:    Train Sequence Recall 0.33058
wandb:                      lr: 1e-05
wandb:          train Totalloss 0.25475
wandb:              train loss1 0.21918
wandb:              train loss2 0.27
wandb: 


```



```Python

lr = 1e-3
alpha = 0.3
lossfunction = torch.nn.CrossEntropyLoss()
loss1 = 0
loss2 = 0
loss = 0
#epochs = 2
evaluation_epochs = 1

wandb: 
wandb: Run summary:
wandb:       Sentence Precision 0.71875
wandb:       Sequence Precision 0.6875
wandb:  Train Sentence F1 Score 0.87771
wandb: Train Sentence Precision 0.82812
wandb:    Train Sentence Recall 0.94488
wandb:  Train Sequence F1 Score 0.87771
wandb: Train Sequence Precision 0.82812
wandb:    Train Sequence Recall 0.94488
wandb:                      lr: 0.001
wandb:          train Totalloss 0.02351
wandb:              train loss1 0.02004
wandb:              train loss2 0.025
```

```Python

#alpha = 0.4
wandb: Run summary:
wandb:       Sentence Precision 0.71875
wandb:       Sequence Precision 0.76562
wandb:  Train Sentence F1 Score 0.898
wandb: Train Sentence Precision 0.875
wandb:    Train Sentence Recall 0.93277
wandb:  Train Sequence F1 Score 0.898
wandb: Train Sequence Precision 0.875
wandb:    Train Sequence Recall 0.93277
wandb:                      lr: 0.001
wandb:          train Totalloss 0.02648
wandb:              train loss1 0.02583
wandb:              train loss2 0.02691
    
wandb: Syncing run cosmic-bird-34
#alpha = 0.5
wandb: 
wandb: Run summary:
wandb:       Sentence Precision 0.67188
wandb:       Sequence Precision 0.67188
wandb:  Train Sentence F1 Score 0.71796
wandb: Train Sentence Precision 0.64062
wandb:    Train Sentence Recall 0.82927
wandb:  Train Sequence F1 Score 0.74683
wandb: Train Sequence Precision 0.6875
wandb:    Train Sequence Recall 0.82927
wandb:                      lr: 0.001
wandb:          train Totalloss 0.08106
wandb:              train loss1 0.06618
wandb:              train loss2 0.09593
    
#alpha = 0.6
wandb: Syncing run ancient-cosmos-36
andb: 
wandb: Run summary:
wandb:       Sentence Precision 0.60938
wandb:       Sequence Precision 0.57812
wandb:  Train Sentence F1 Score 0.66006
wandb: Train Sentence Precision 0.59375
wandb:    Train Sentence Recall 0.75556
wandb:  Train Sequence F1 Score 0.66973
wandb: Train Sequence Precision 0.60938
wandb:    Train Sequence Recall 0.75556
wandb:                      lr: 0.001
wandb:          train Totalloss 0.10129
wandb:              train loss1 0.09979
wandb:              train loss2 0.10354
wandb: 
    
#alpha = 0.7
wandb: Syncing run fresh-cloud-37
    
    wandb: Run summary:
wandb:       Sentence Precision 0.70312
wandb:       Sequence Precision 0.71875
wandb:  Train Sentence F1 Score 0.53713
wandb: Train Sentence Precision 0.46875
wandb:    Train Sentence Recall 0.64228
wandb:  Train Sequence F1 Score 0.56713
wandb: Train Sequence Precision 0.51562
wandb:    Train Sequence Recall 0.64228
wandb:                      lr: 0.001
wandb:          train Totalloss 0.13506
wandb:              train loss1 0.12427
wandb:              train loss2 0.16026
```

```Python
#epochs = 2

wandb: Run summary:
wandb:       Sentence Precision 0.71875
wandb:       Sequence Precision 0.73438
wandb:  Train Sentence F1 Score 0.85701
wandb: Train Sentence Precision 0.84375
wandb:    Train Sentence Recall 0.87069
wandb:  Train Sequence F1 Score 0.83215
wandb: Train Sequence Precision 0.79688
wandb:    Train Sequence Recall 0.87069
wandb:                      lr: 0.001
wandb:          train Totalloss 0.04113
wandb:              train loss1 0.02849
wandb:              train loss2 0.04655

epoch=3

andb: Run summary:
wandb:       Sentence Precision 0.70312
wandb:       Sequence Precision 0.67188
wandb:  Train Sentence F1 Score 0.92902
wandb: Train Sentence Precision 0.92188
wandb:    Train Sentence Recall 0.94643
wandb:  Train Sequence F1 Score 0.91271
wandb: Train Sequence Precision 0.89062
wandb:    Train Sequence Recall 0.94643
wandb:                      lr: 0.001
wandb:          train Totalloss 0.01576
wandb:              train loss1 0.01462
wandb:              train loss2 0.01651


epoch=4
wandb: Run summary:
wandb:       Sentence Precision 0.67188
wandb:       Sequence Precision 0.64062
wandb:  Train Sentence F1 Score 0.90243
wandb: Train Sentence Precision 0.89062
wandb:    Train Sentence Recall 0.92481
wandb:  Train Sequence F1 Score 0.86885
wandb: Train Sequence Precision 0.82812
wandb:    Train Sequence Recall 0.92481
wandb:                      lr: 0.001
wandb:          train Totalloss 0.03759
wandb:              train loss1 0.03039
wandb:              train loss2 0.04068

wandb: Syncing run fiery-spaceship-35
epoch = 5
wandb: 
wandb: Run summary:
wandb:       Sentence Precision 0.71875
wandb:       Sequence Precision 0.75
wandb:  Train Sentence F1 Score 0.91675
wandb: Train Sentence Precision 0.92188
wandb:    Train Sentence Recall 0.92157
wandb:  Train Sequence F1 Score 0.91675
wandb: Train Sequence Precision 0.92188
wandb:    Train Sequence Recall 0.92157
wandb:                      lr: 0.001
wandb:          train Totalloss 0.01513
wandb:              train loss1 0.01398
wandb:              train loss2 0.01562
wandb: 

wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-fog-38
epoch = 6
wandb: Run summary:
wandb:       Sentence Precision 0.70312
wandb:       Sequence Precision 0.6875
wandb:  Train Sentence F1 Score 0.89688
wandb: Train Sentence Precision 0.85938
wandb:    Train Sentence Recall 0.94872
wandb:  Train Sequence F1 Score 0.8704
wandb: Train Sequence Precision 0.8125
wandb:    Train Sequence Recall 0.94872
wandb:                      lr: 0.001
wandb:          train Totalloss 0.0215
wandb:              train loss1 0.01617
wandb:              train loss2 0
    
    
epoch=7
wandb: 
wandb: Run summary:
wandb:       Sentence Precision 0.70312
wandb:       Sequence Precision 0.70312
wandb:  Train Sentence F1 Score 0.84494
wandb: Train Sentence Precision 0.8125
wandb:    Train Sentence Recall 0.89091
wandb:  Train Sequence F1 Score 0.79071
wandb: Train Sequence Precision 0.71875
wandb:    Train Sequence Recall 0.89091
wandb:                      lr: 0.001
wandb:          train Totalloss 0.04726
wandb:              train loss1 0.03774
wandb:              train loss2 0.05135
    epoch=8
    wandb: Run summary:
wandb:       Sentence Precision 0.76562
wandb:       Sequence Precision 0.75
wandb:  Train Sentence F1 Score 0.83371
wandb: Train Sentence Precision 0.78125
wandb:    Train Sentence Recall 0.90517
wandb:  Train Sequence F1 Score 0.82464
wandb: Train Sequence Precision 0.76562
wandb:    Train Sequence Recall 0.90517
wandb:                      lr: 0.001
wandb:          train Totalloss 0.03547
wandb:              train loss1 0.02558
wandb:              train loss2 0.03971
wandb: 
    epoch=9
    wandb: Run summary:
wandb:       Sentence Precision 0.79688
wandb:       Sequence Precision 0.75
wandb:  Train Sentence F1 Score 0.85138
wandb: Train Sentence Precision 0.8125
wandb:    Train Sentence Recall 0.90517
wandb:  Train Sequence F1 Score 0.84263
wandb: Train Sequence Precision 0.79688
wandb:    Train Sequence Recall 0.90517
wandb:                      lr: 0.001
wandb:          train Totalloss 0.04387
wandb:              train loss1 0.03724
wandb:              train loss2 0.04672
wandb: 
    
epoch=10
andb: Run summary:
wandb:       Sentence Precision 0.76562
wandb:       Sequence Precision 0.70312
wandb:  Train Sentence F1 Score 0.90683
wandb: Train Sentence Precision 0.90625
wandb:    Train Sentence Recall 0.91743
wandb:  Train Sequence F1 Score 0.89886
wandb: Train Sequence Precision 0.89062
wandb:    Train Sequence Recall 0.91743
wandb:                      lr: 0.001
wandb:          train Totalloss 0.02355
wandb:              train loss1 0.01798
wandb:              train loss2 0.02593
wandb: Run summary:
        
        
 epoch=11
wandb:       Sentence Precision 0.76562
wandb:       Sequence Precision 0.76562
wandb:  Train Sentence F1 Score 0.9345
wandb: Train Sentence Precision 0.90625
wandb:    Train Sentence Recall 0.97521
wandb:  Train Sequence F1 Score 0.92604
wandb: Train Sequence Precision 0.89062
wandb:    Train Sequence Recall 0.97521
wandb:                      lr: 0.001
wandb:          train Totalloss 0.02388
wandb:              train loss1 0.02033
wandb:              train loss2 0.0254
    
    
epoch=12
wandb: Run summary:
wandb:       Sentence Precision 0.5625
wandb:       Sequence Precision 0.59375
wandb:  Train Sentence F1 Score 0.89437
wandb: Train Sentence Precision 0.82812
wandb:    Train Sentence Recall 0.98387
wandb:  Train Sequence F1 Score 0.86602
wandb: Train Sequence Precision 0.78125
wandb:    Train Sequence Recall 0.98387
wandb:                      lr: 0.001
wandb:          train Totalloss 0.02636
wandb:              train loss1 0.02288
wandb:              train loss2 0.02786
    
    
    epoch=13
    wandb: 
wandb: Run summary:
wandb:       Sentence Precision 0.65625
wandb:       Sequence Precision 0.67188
wandb:  Train Sentence F1 Score 0.84206
wandb: Train Sentence Precision 0.8125
wandb:    Train Sentence Recall 0.88462
wandb:  Train Sequence F1 Score 0.85047
wandb: Train Sequence Precision 0.82812
wandb:    Train Sequence Recall 0.88462
wandb:                      lr: 0.001
wandb:          train Totalloss 0.04186
wandb:              train loss1 0.03568
wandb:              train loss2 0.04451
wandb: 
```



_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

```
epoch=2
wandb: Run summary:
wandb:       Sentence Precision 0.70312
wandb:       Sequence Precision 0.70312
wandb:  Train Sentence F1 Score 0.87024
wandb: Train Sentence Precision 0.84375
wandb:    Train Sentence Recall 0.90909
wandb:  Train Sequence F1 Score 0.84434
wandb: Train Sequence Precision 0.79688
wandb:    Train Sequence Recall 0.90909
wandb:                      lr: 0.001
wandb:          train Totalloss 0.0312
wandb:              train loss1 0.02719
wandb:              train loss2 0.03292



e
wandb: 3
wandb: Run summary:
wandb:       Sentence Precision 0.67188
wandb:       Sequence Precision 0.67188
wandb:  Train Sentence F1 Score 0.88801
wandb: Train Sentence Precision 0.84375
wandb:    Train Sentence Recall 0.94828
wandb:  Train Sequence F1 Score 0.88801
wandb: Train Sequence Precision 0.84375
wandb:    Train Sequence Recall 0.94828
wandb:                      lr: 0.001
wandb:          train Totalloss 0.02452
wandb:              train loss1 0.01934
wandb:              train loss2 0.02674
wandb: 
```

